#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å€ºåŠ¡æ¸…ç†è¿›åº¦è·Ÿè¸ªå™¨

è·Ÿè¸ªå’Œç›‘æ§æŠ€æœ¯å€ºåŠ¡æ¸…ç†çš„è¿›åº¦ï¼ŒåŒ…æ‹¬ï¼š
- ä»»åŠ¡è¿›åº¦è·Ÿè¸ª
- è´¨é‡æŒ‡æ ‡ç›‘æ§
- æ€§èƒ½åŸºå‡†æµ‹è¯•
- æ¸…ç†æ•ˆæœè¯„ä¼°
"""

import time
import psutil
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import json
import sqlite3
import threading


@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡"""
    timestamp: datetime
    total_lines: int
    code_lines: int
    comment_lines: int
    blank_lines: int
    cyclomatic_complexity: float
    test_coverage: float
    duplicate_code_ratio: float
    technical_debt_ratio: float
    maintainability_index: float


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    timestamp: datetime
    startup_time: float  # å¯åŠ¨æ—¶é—´ï¼ˆç§’ï¼‰
    memory_usage: float  # å†…å­˜ä½¿ç”¨ï¼ˆMBï¼‰
    cpu_usage: float     # CPUä½¿ç”¨ç‡ï¼ˆ%ï¼‰
    build_time: float    # æ„å»ºæ—¶é—´ï¼ˆç§’ï¼‰
    test_execution_time: float  # æµ‹è¯•æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰


@dataclass
class TaskProgress:
    """ä»»åŠ¡è¿›åº¦"""
    task_id: str
    status: str
    progress_percent: float
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    estimated_completion: Optional[datetime] = None
    actual_hours: float = 0.0
    estimated_hours: float = 0.0
    notes: str = ""


class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨"""
    
    def __init__(self, db_path: str = "debt_cleanup_progress.db"):
        self.db_path = db_path
        self.project_root = Path(".")
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()
        
        # ç›‘æ§çº¿ç¨‹
        self._monitoring = False
        self._monitor_thread = None
        
        # åŸºå‡†æŒ‡æ ‡
        self.baseline_metrics = None
    
    def _init_database(self) -> None:
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºè¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS quality_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                total_lines INTEGER,
                code_lines INTEGER,
                comment_lines INTEGER,
                blank_lines INTEGER,
                cyclomatic_complexity REAL,
                test_coverage REAL,
                duplicate_code_ratio REAL,
                technical_debt_ratio REAL,
                maintainability_index REAL
            )
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS performance_metrics (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT NOT NULL,
                startup_time REAL,
                memory_usage REAL,
                cpu_usage REAL,
                build_time REAL,
                test_execution_time REAL
            )
        """)
        
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS task_progress (
                task_id TEXT PRIMARY KEY,
                status TEXT NOT NULL,
                progress_percent REAL,
                start_time TEXT,
                end_time TEXT,
                estimated_completion TEXT,
                actual_hours REAL,
                estimated_hours REAL,
                notes TEXT
            )
        """)
        
        conn.commit()
        conn.close()
    
    def start_monitoring(self, interval: int = 300) -> None:
        """å¼€å§‹ç›‘æ§ï¼ˆæ¯5åˆ†é’Ÿæ”¶é›†ä¸€æ¬¡æŒ‡æ ‡ï¼‰"""
        if self._monitoring:
            return
        
        self._monitoring = True
        self._monitor_thread = threading.Thread(
            target=self._monitor_loop,
            args=(interval,),
            daemon=True
        )
        self._monitor_thread.start()
    
    def stop_monitoring(self) -> None:
        """åœæ­¢ç›‘æ§"""
        self._monitoring = False
        if self._monitor_thread:
            self._monitor_thread.join()
    
    def _monitor_loop(self, interval: int) -> None:
        """ç›‘æ§å¾ªç¯"""
        while self._monitoring:
            try:
                # æ”¶é›†è´¨é‡æŒ‡æ ‡
                quality_metrics = self._collect_quality_metrics()
                if quality_metrics:
                    self._save_quality_metrics(quality_metrics)
                
                # æ”¶é›†æ€§èƒ½æŒ‡æ ‡
                performance_metrics = self._collect_performance_metrics()
                if performance_metrics:
                    self._save_performance_metrics(performance_metrics)
                
            except Exception as e:
                print(f"ç›‘æ§è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š{e}")
            
            time.sleep(interval)
    
    def _collect_quality_metrics(self) -> Optional[QualityMetrics]:
        """æ”¶é›†è´¨é‡æŒ‡æ ‡"""
        try:
            # ç»Ÿè®¡ä»£ç è¡Œæ•°
            total_lines, code_lines, comment_lines, blank_lines = self._count_lines()
            
            # è®¡ç®—åœˆå¤æ‚åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
            complexity = self._calculate_complexity()
            
            # è·å–æµ‹è¯•è¦†ç›–ç‡
            coverage = self._get_test_coverage()
            
            # è®¡ç®—é‡å¤ä»£ç æ¯”ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
            duplicate_ratio = self._calculate_duplicate_ratio()
            
            # è®¡ç®—æŠ€æœ¯å€ºåŠ¡æ¯”ç‡
            debt_ratio = self._calculate_debt_ratio()
            
            # è®¡ç®—å¯ç»´æŠ¤æ€§æŒ‡æ•°
            maintainability = self._calculate_maintainability_index(
                complexity, coverage, duplicate_ratio
            )
            
            return QualityMetrics(
                timestamp=datetime.now(),
                total_lines=total_lines,
                code_lines=code_lines,
                comment_lines=comment_lines,
                blank_lines=blank_lines,
                cyclomatic_complexity=complexity,
                test_coverage=coverage,
                duplicate_code_ratio=duplicate_ratio,
                technical_debt_ratio=debt_ratio,
                maintainability_index=maintainability
            )
            
        except Exception as e:
            print(f"æ”¶é›†è´¨é‡æŒ‡æ ‡å¤±è´¥ï¼š{e}")
            return None
    
    def _collect_performance_metrics(self) -> Optional[PerformanceMetrics]:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        try:
            # æµ‹é‡å¯åŠ¨æ—¶é—´
            startup_time = self._measure_startup_time()
            
            # è·å–å½“å‰å†…å­˜ä½¿ç”¨
            memory_usage = psutil.virtual_memory().used / 1024 / 1024  # MB
            
            # è·å–å½“å‰CPUä½¿ç”¨ç‡
            cpu_usage = psutil.cpu_percent(interval=1)
            
            # æµ‹é‡æ„å»ºæ—¶é—´
            build_time = self._measure_build_time()
            
            # æµ‹é‡æµ‹è¯•æ‰§è¡Œæ—¶é—´
            test_time = self._measure_test_time()
            
            return PerformanceMetrics(
                timestamp=datetime.now(),
                startup_time=startup_time,
                memory_usage=memory_usage,
                cpu_usage=cpu_usage,
                build_time=build_time,
                test_execution_time=test_time
            )
            
        except Exception as e:
            print(f"æ”¶é›†æ€§èƒ½æŒ‡æ ‡å¤±è´¥ï¼š{e}")
            return None
    
    def _count_lines(self) -> tuple:
        """ç»Ÿè®¡ä»£ç è¡Œæ•°"""
        total_lines = 0
        code_lines = 0
        comment_lines = 0
        blank_lines = 0
        
        for py_file in self.project_root.rglob("*.py"):
            if "__pycache__" in str(py_file) or ".venv" in str(py_file):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                for line in lines:
                    total_lines += 1
                    stripped = line.strip()
                    
                    if not stripped:
                        blank_lines += 1
                    elif stripped.startswith('#'):
                        comment_lines += 1
                    else:
                        code_lines += 1
                        
            except Exception:
                continue
        
        return total_lines, code_lines, comment_lines, blank_lines
    
    def _calculate_complexity(self) -> float:
        """è®¡ç®—å¹³å‡åœˆå¤æ‚åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            # ä½¿ç”¨radonå·¥å…·è®¡ç®—å¤æ‚åº¦
            result = subprocess.run(
                ["python", "-m", "radon", "cc", "src", "--average"],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            if result.returncode == 0:
                # è§£æè¾“å‡ºè·å–å¹³å‡å¤æ‚åº¦
                output = result.stdout
                # ç®€åŒ–è§£æï¼Œå®é™…éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
                return 2.5  # é»˜è®¤å€¼
            
        except Exception:
            pass
        
        return 2.5  # é»˜è®¤å¤æ‚åº¦
    
    def _get_test_coverage(self) -> float:
        """è·å–æµ‹è¯•è¦†ç›–ç‡"""
        try:
            # è¿è¡Œcoverageå·¥å…·
            result = subprocess.run(
                ["python", "-m", "coverage", "report", "--format=json"],
                capture_output=True,
                text=True,
                timeout=60
            )
            
            if result.returncode == 0:
                coverage_data = json.loads(result.stdout)
                return coverage_data.get("totals", {}).get("percent_covered", 0.0)
            
        except Exception:
            pass
        
        return 0.0  # é»˜è®¤è¦†ç›–ç‡
    
    def _calculate_duplicate_ratio(self) -> float:
        """è®¡ç®—é‡å¤ä»£ç æ¯”ç‡ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # è¿™é‡Œéœ€è¦å®ç°ä»£ç é‡å¤æ£€æµ‹ç®—æ³•
        # ç®€åŒ–å®ç°ï¼Œè¿”å›ä¼°ç®—å€¼
        return 15.0  # 15%é‡å¤ç‡
    
    def _calculate_debt_ratio(self) -> float:
        """è®¡ç®—æŠ€æœ¯å€ºåŠ¡æ¯”ç‡"""
        # åŸºäºå·²çŸ¥é—®é¢˜æ•°é‡è®¡ç®—å€ºåŠ¡æ¯”ç‡
        # è¿™é‡Œå¯ä»¥é›†æˆdebt_analyzerçš„ç»“æœ
        return 25.0  # 25%å€ºåŠ¡æ¯”ç‡
    
    def _calculate_maintainability_index(self, complexity: float, coverage: float, duplicate_ratio: float) -> float:
        """è®¡ç®—å¯ç»´æŠ¤æ€§æŒ‡æ•°"""
        # ç®€åŒ–çš„å¯ç»´æŠ¤æ€§æŒ‡æ•°è®¡ç®—
        # å®é™…å…¬å¼æ›´å¤æ‚ï¼Œè€ƒè™‘å¤šä¸ªå› ç´ 
        base_score = 100
        complexity_penalty = complexity * 5
        coverage_bonus = coverage * 0.3
        duplicate_penalty = duplicate_ratio * 2
        
        score = base_score - complexity_penalty + coverage_bonus - duplicate_penalty
        return max(0, min(100, score))
    
    def _measure_startup_time(self) -> float:
        """æµ‹é‡åº”ç”¨å¯åŠ¨æ—¶é—´"""
        try:
            start_time = time.time()
            result = subprocess.run(
                ["python", "main.py", "--version"],
                capture_output=True,
                timeout=30
            )
            end_time = time.time()
            
            if result.returncode == 0:
                return end_time - start_time
            
        except Exception:
            pass
        
        return 0.0
    
    def _measure_build_time(self) -> float:
        """æµ‹é‡æ„å»ºæ—¶é—´"""
        try:
            start_time = time.time()
            result = subprocess.run(
                ["python", "-m", "py_compile", "src/main.py"],
                capture_output=True,
                timeout=60
            )
            end_time = time.time()
            
            if result.returncode == 0:
                return end_time - start_time
            
        except Exception:
            pass
        
        return 0.0
    
    def _measure_test_time(self) -> float:
        """æµ‹é‡æµ‹è¯•æ‰§è¡Œæ—¶é—´"""
        try:
            start_time = time.time()
            result = subprocess.run(
                ["python", "-m", "pytest", "tests/", "-v"],
                capture_output=True,
                timeout=300
            )
            end_time = time.time()
            
            return end_time - start_time
            
        except Exception:
            pass
        
        return 0.0
    
    def _save_quality_metrics(self, metrics: QualityMetrics) -> None:
        """ä¿å­˜è´¨é‡æŒ‡æ ‡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO quality_metrics (
                timestamp, total_lines, code_lines, comment_lines, blank_lines,
                cyclomatic_complexity, test_coverage, duplicate_code_ratio,
                technical_debt_ratio, maintainability_index
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            metrics.timestamp.isoformat(),
            metrics.total_lines,
            metrics.code_lines,
            metrics.comment_lines,
            metrics.blank_lines,
            metrics.cyclomatic_complexity,
            metrics.test_coverage,
            metrics.duplicate_code_ratio,
            metrics.technical_debt_ratio,
            metrics.maintainability_index
        ))
        
        conn.commit()
        conn.close()
    
    def _save_performance_metrics(self, metrics: PerformanceMetrics) -> None:
        """ä¿å­˜æ€§èƒ½æŒ‡æ ‡"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO performance_metrics (
                timestamp, startup_time, memory_usage, cpu_usage,
                build_time, test_execution_time
            ) VALUES (?, ?, ?, ?, ?, ?)
        """, (
            metrics.timestamp.isoformat(),
            metrics.startup_time,
            metrics.memory_usage,
            metrics.cpu_usage,
            metrics.build_time,
            metrics.test_execution_time
        ))
        
        conn.commit()
        conn.close()
    
    def update_task_progress(self, task_id: str, status: str, progress_percent: float = None, notes: str = "") -> None:
        """æ›´æ–°ä»»åŠ¡è¿›åº¦"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–ç°æœ‰è®°å½•
        cursor.execute("SELECT * FROM task_progress WHERE task_id = ?", (task_id,))
        existing = cursor.fetchone()
        
        now = datetime.now().isoformat()
        
        if existing:
            # æ›´æ–°ç°æœ‰è®°å½•
            update_fields = ["status = ?", "notes = ?", "end_time = ?"]
            update_values = [status, notes, now if status in ["completed", "failed"] else None]
            
            if progress_percent is not None:
                update_fields.append("progress_percent = ?")
                update_values.append(progress_percent)
            
            update_values.append(task_id)
            
            cursor.execute(
                f"UPDATE task_progress SET {', '.join(update_fields)} WHERE task_id = ?",
                update_values
            )
        else:
            # åˆ›å»ºæ–°è®°å½•
            cursor.execute("""
                INSERT INTO task_progress (
                    task_id, status, progress_percent, start_time, notes
                ) VALUES (?, ?, ?, ?, ?)
            """, (
                task_id,
                status,
                progress_percent or 0.0,
                now,
                notes
            ))
        
        conn.commit()
        conn.close()
    
    def get_progress_summary(self) -> Dict[str, Any]:
        """è·å–è¿›åº¦æ‘˜è¦"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ä»»åŠ¡ç»Ÿè®¡
        cursor.execute("""
            SELECT status, COUNT(*), AVG(progress_percent)
            FROM task_progress
            GROUP BY status
        """)
        task_stats = {row[0]: {"count": row[1], "avg_progress": row[2]} for row in cursor.fetchall()}
        
        # æœ€æ–°è´¨é‡æŒ‡æ ‡
        cursor.execute("""
            SELECT * FROM quality_metrics
            ORDER BY timestamp DESC
            LIMIT 1
        """)
        latest_quality = cursor.fetchone()
        
        # æœ€æ–°æ€§èƒ½æŒ‡æ ‡
        cursor.execute("""
            SELECT * FROM performance_metrics
            ORDER BY timestamp DESC
            LIMIT 1
        """)
        latest_performance = cursor.fetchone()
        
        conn.close()
        
        return {
            "task_statistics": task_stats,
            "latest_quality_metrics": latest_quality,
            "latest_performance_metrics": latest_performance,
            "last_updated": datetime.now().isoformat()
        }
    
    def generate_trend_report(self, days: int = 30) -> str:
        """ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Š"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # è·å–æŒ‡å®šå¤©æ•°å†…çš„æ•°æ®
        since_date = (datetime.now() - timedelta(days=days)).isoformat()
        
        # è´¨é‡è¶‹åŠ¿
        cursor.execute("""
            SELECT timestamp, maintainability_index, test_coverage, technical_debt_ratio
            FROM quality_metrics
            WHERE timestamp >= ?
            ORDER BY timestamp
        """, (since_date,))
        quality_data = cursor.fetchall()
        
        # æ€§èƒ½è¶‹åŠ¿
        cursor.execute("""
            SELECT timestamp, startup_time, memory_usage, build_time
            FROM performance_metrics
            WHERE timestamp >= ?
            ORDER BY timestamp
        """, (since_date,))
        performance_data = cursor.fetchall()
        
        conn.close()
        
        # ç”ŸæˆæŠ¥å‘Š
        report = []
        report.append("# ğŸ“ˆ å€ºåŠ¡æ¸…ç†è¶‹åŠ¿æŠ¥å‘Š")
        report.append("")
        report.append(f"**æŠ¥å‘Šå‘¨æœŸ**: æœ€è¿‘ {days} å¤©")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        if quality_data:
            first_quality = quality_data[0]
            last_quality = quality_data[-1]
            
            report.append("## ğŸ“Š è´¨é‡æŒ‡æ ‡è¶‹åŠ¿")
            report.append("")
            report.append(f"- **å¯ç»´æŠ¤æ€§æŒ‡æ•°**: {first_quality[1]:.1f} â†’ {last_quality[1]:.1f} ({last_quality[1] - first_quality[1]:+.1f})")
            report.append(f"- **æµ‹è¯•è¦†ç›–ç‡**: {first_quality[2]:.1f}% â†’ {last_quality[2]:.1f}% ({last_quality[2] - first_quality[2]:+.1f}%)")
            report.append(f"- **æŠ€æœ¯å€ºåŠ¡æ¯”ç‡**: {first_quality[3]:.1f}% â†’ {last_quality[3]:.1f}% ({last_quality[3] - first_quality[3]:+.1f}%)")
            report.append("")
        
        if performance_data:
            first_perf = performance_data[0]
            last_perf = performance_data[-1]
            
            report.append("## âš¡ æ€§èƒ½æŒ‡æ ‡è¶‹åŠ¿")
            report.append("")
            report.append(f"- **å¯åŠ¨æ—¶é—´**: {first_perf[1]:.2f}s â†’ {last_perf[1]:.2f}s ({last_perf[1] - first_perf[1]:+.2f}s)")
            report.append(f"- **å†…å­˜ä½¿ç”¨**: {first_perf[2]:.1f}MB â†’ {last_perf[2]:.1f}MB ({last_perf[2] - first_perf[2]:+.1f}MB)")
            report.append(f"- **æ„å»ºæ—¶é—´**: {first_perf[3]:.2f}s â†’ {last_perf[3]:.2f}s ({last_perf[3] - first_perf[3]:+.2f}s)")
            report.append("")
        
        # æ”¹è¿›å»ºè®®
        report.append("## ğŸ’¡ æ”¹è¿›å»ºè®®")
        report.append("")
        
        if quality_data and len(quality_data) >= 2:
            latest = quality_data[-1]
            if latest[1] < 60:  # å¯ç»´æŠ¤æ€§æŒ‡æ•°ä½äº60
                report.append("- ğŸ”´ **å¯ç»´æŠ¤æ€§æŒ‡æ•°åä½**ï¼Œå»ºè®®ä¼˜å…ˆå¤„ç†ä»£ç é‡æ„ä»»åŠ¡")
            if latest[2] < 80:  # æµ‹è¯•è¦†ç›–ç‡ä½äº80%
                report.append("- ğŸŸ¡ **æµ‹è¯•è¦†ç›–ç‡ä¸è¶³**ï¼Œå»ºè®®å¢åŠ å•å…ƒæµ‹è¯•")
            if latest[3] > 20:  # æŠ€æœ¯å€ºåŠ¡æ¯”ç‡é«˜äº20%
                report.append("- ğŸ”´ **æŠ€æœ¯å€ºåŠ¡æ¯”ç‡è¿‡é«˜**ï¼Œå»ºè®®åŠ å¿«å€ºåŠ¡æ¸…ç†è¿›åº¦")
        
        return "\n".join(report)
    
    def set_baseline(self) -> None:
        """è®¾ç½®åŸºå‡†æŒ‡æ ‡"""
        quality_metrics = self._collect_quality_metrics()
        performance_metrics = self._collect_performance_metrics()
        
        self.baseline_metrics = {
            "quality": quality_metrics,
            "performance": performance_metrics,
            "timestamp": datetime.now()
        }
        
        # ä¿å­˜åŸºå‡†æŒ‡æ ‡
        if quality_metrics:
            self._save_quality_metrics(quality_metrics)
        if performance_metrics:
            self._save_performance_metrics(performance_metrics)
    
    def export_data(self, output_path: str) -> None:
        """å¯¼å‡ºæ‰€æœ‰æ•°æ®"""
        conn = sqlite3.connect(self.db_path)
        
        # å¯¼å‡ºä¸ºJSONæ ¼å¼
        data = {
            "quality_metrics": [],
            "performance_metrics": [],
            "task_progress": []
        }
        
        # è´¨é‡æŒ‡æ ‡
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM quality_metrics ORDER BY timestamp")
        for row in cursor.fetchall():
            data["quality_metrics"].append({
                "timestamp": row[1],
                "total_lines": row[2],
                "code_lines": row[3],
                "comment_lines": row[4],
                "blank_lines": row[5],
                "cyclomatic_complexity": row[6],
                "test_coverage": row[7],
                "duplicate_code_ratio": row[8],
                "technical_debt_ratio": row[9],
                "maintainability_index": row[10]
            })
        
        # æ€§èƒ½æŒ‡æ ‡
        cursor.execute("SELECT * FROM performance_metrics ORDER BY timestamp")
        for row in cursor.fetchall():
            data["performance_metrics"].append({
                "timestamp": row[1],
                "startup_time": row[2],
                "memory_usage": row[3],
                "cpu_usage": row[4],
                "build_time": row[5],
                "test_execution_time": row[6]
            })
        
        # ä»»åŠ¡è¿›åº¦
        cursor.execute("SELECT * FROM task_progress")
        for row in cursor.fetchall():
            data["task_progress"].append({
                "task_id": row[0],
                "status": row[1],
                "progress_percent": row[2],
                "start_time": row[3],
                "end_time": row[4],
                "estimated_completion": row[5],
                "actual_hours": row[6],
                "estimated_hours": row[7],
                "notes": row[8]
            })
        
        conn.close()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    tracker = ProgressTracker()
    
    # è®¾ç½®åŸºå‡†
    tracker.set_baseline()
    
    # å¼€å§‹ç›‘æ§
    tracker.start_monitoring(interval=60)  # æ¯åˆ†é’Ÿæ”¶é›†ä¸€æ¬¡
    
    # æ¨¡æ‹Ÿä»»åŠ¡è¿›åº¦æ›´æ–°
    tracker.update_task_progress("task_001", "in_progress", 50.0, "å¼€å§‹å¤„ç†ç¡¬ç¼–ç å¯¼å…¥")
    
    # ç”ŸæˆæŠ¥å‘Š
    summary = tracker.get_progress_summary()
    print(f"è¿›åº¦æ‘˜è¦ï¼š{summary}")
    
    # ç”Ÿæˆè¶‹åŠ¿æŠ¥å‘Š
    trend_report = tracker.generate_trend_report(7)  # æœ€è¿‘7å¤©
    with open("trend_report.md", "w", encoding="utf-8") as f:
        f.write(trend_report)
    
    # å¯¼å‡ºæ•°æ®
    tracker.export_data("progress_data.json")
    
    # åœæ­¢ç›‘æ§
    time.sleep(5)
    tracker.stop_monitoring()